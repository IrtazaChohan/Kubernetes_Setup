# Bootstrapping the Cluster - after installation of 

# On the Kube master node, initialize the cluster - we pass a networking flag (may take a few minutes to complete)
sudo kubeadm init --pod-network-cidr=10.244.0.0/16

#When it is done, set up the local kubeconfig - look at the output of the above command and that shows what you need to run
# Once the below are complete then you should have the Kubernestes master up and running!
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

#Verify that the cluster is responsive and that Kubectl is working:
kubectl version

# You should get Server Version as well as Client Version. Your mainly looking for a server version which proves that you were able to communicate with the API and get a response back using kubectl.
# Output should look something like this:
Client Version: version.Info{Major:"1", Minor:"12", GitVersion:"v1.12.7", GitCommit:"6f482974b76db3f1e0f5d24605a9d1d38fad9a2b", GitTreeState:"clean", BuildDate:"2019-03-25T02:52:13Z", GoVersion:"go1.10.8", Compiler:"gc", Platform:"linux/amd64"}
Server Version: version.Info{Major:"1", Minor:"12", GitVersion:"v1.12.10", GitCommit:"e3c134023df5dea457638b614ee17ef234dc34a6", GitTreeState:"clean", BuildDate:"2019-07-08T03:40:54Z", GoVersion:"go1.10.8", Compiler:"gc", Platform:"linux/amd64"}

# Your now ready to join your worker nodes to the cluster - again you can find this command also from the output of the kubeadm init command we did initially.
# The kubeadm init command should output a kubeadm join command containing a token and hash. Copy that command and run it with sudo on both worker nodes. 
# It should look something like this:
sudo kubeadm join <IP>:6443 --token <token> --discovery-token-ca-cert-hash <Hash>
#my example:
kubeadm join 172.31.114.126:6443 --token txpzuj.pi01ikwoy9q9w0ma --discovery-token-ca-cert-hash sha256:4e8a6ab86630ba07023f1d87c55327cde52f126d54631bb51732d742ecde2560

#Verify that all nodes have successfully joined the cluster - run the below command on the master node:
kubectl get nodes

# You should see all three of your nodes listed. It should look something like this:
# The nodes are expected to have a STATUS of NotReady at this point since networking has not been setup yet - thats next.
NAME                      STATUS     ROLES    AGE     VERSION
<server1>   NotReady   master   5m17s   v1.12.2
<server2>   NotReady   <none>   53s     v1.12.2
<server3>   NotReady   <none>   31s     v1.12.2

